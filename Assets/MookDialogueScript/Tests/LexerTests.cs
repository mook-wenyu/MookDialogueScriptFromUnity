using System;
using System.Collections.Generic;
using System.Linq;
using NUnit.Framework;
using UnityEngine;

namespace MookDialogueScript.Tests
{
    /// <summary>
    /// è¯æ³•åˆ†æå™¨æµ‹è¯•
    /// </summary>
    public class LexerTests
    {
        /// <summary>
        /// åˆ›å»ºè¯æ³•åˆ†æå™¨å¹¶è·å–Tokenåˆ—è¡¨
        /// </summary>
        private List<Token> TokenizeScript(string script)
        {
            var lexer = new Lexer(script);
            var tokens = lexer.Tokenize();
            foreach (var token in tokens)
            {
                Debug.Log(token.ToString());
            }
            return tokens;
        }

        /// <summary>
        /// éªŒè¯Tokenåºåˆ—
        /// </summary>
        private void AssertTokens(List<Token> tokens, params (TokenType type, string value)[] expectedTokens)
        {
            // è¿‡æ»¤æ‰NEWLINE tokenä»¥ç®€åŒ–æµ‹è¯•
            var filteredTokens = tokens.Where(t => t.Type != TokenType.NEWLINE).ToList();

            Assert.AreEqual(expectedTokens.Length + 1, filteredTokens.Count, "Tokenæ•°é‡ä¸åŒ¹é…ï¼ˆåŒ…æ‹¬EOFï¼‰");

            for (int i = 0; i < expectedTokens.Length; i++)
            {
                var expected = expectedTokens[i];
                var actual = filteredTokens[i];
                Assert.AreEqual(expected.type, actual.Type, $"ç¬¬{i}ä¸ªTokenç±»å‹ä¸åŒ¹é…");
                Assert.AreEqual(expected.value, actual.Value, $"ç¬¬{i}ä¸ªTokenå€¼ä¸åŒ¹é…");
            }

            // æœ€åä¸€ä¸ªåº”è¯¥æ˜¯EOF
            Assert.AreEqual(TokenType.EOF, filteredTokens.Last().Type, "æœ€åä¸€ä¸ªTokenåº”è¯¥æ˜¯EOF");
        }

        [Test]
        public void TestBasicNodeStructure()
        {
            string script = @"node: test
---
è§’è‰²: ä½ å¥½ä¸–ç•Œ
===";

            var tokens = TokenizeScript(script);
            
            AssertTokens(tokens,
                (TokenType.IDENTIFIER, "node"),
                (TokenType.METADATA_SEPARATOR, ":"),
                (TokenType.TEXT, "test"),
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "è§’è‰²"),
                (TokenType.COLON, ":"),
                (TokenType.TEXT, " ä½ å¥½ä¸–ç•Œ"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestVariablesAndInterpolation()
        {
            string script = @"---
è§’è‰²: ä½ å¥½{$name}ï¼Œæ¬¢è¿æ¥åˆ°{$place}
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "è§’è‰²"),
                (TokenType.COLON, ":"),
                (TokenType.TEXT, " ä½ å¥½"),
                (TokenType.LEFT_BRACE, "{"),
                (TokenType.VARIABLE, "name"),
                (TokenType.RIGHT_BRACE, "}"),
                (TokenType.TEXT, "ï¼Œæ¬¢è¿æ¥åˆ°"),
                (TokenType.LEFT_BRACE, "{"),
                (TokenType.VARIABLE, "place"),
                (TokenType.RIGHT_BRACE, "}"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestCommands()
        {
            string script = @"---
<<set $hp = 100>>
<<var $gold 50>>
<<wait 2.0>>
<<jump ending>>
===";

            var tokens = TokenizeScript(script);

            var expectedTokens = new List<(TokenType type, string value)>
            {
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "hp"),
                (TokenType.ASSIGN, "="),
                (TokenType.NUMBER, "100"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.VAR, "var"),
                (TokenType.VARIABLE, "gold"),
                (TokenType.NUMBER, "50"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.WAIT, "wait"),
                (TokenType.NUMBER, "2.0"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.JUMP, "jump"),
                (TokenType.IDENTIFIER, "ending"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            };

            AssertTokens(tokens, expectedTokens.ToArray());
        }

        [Test]
        public void TestChoices()
        {
            string script = @"---
é€‰æ‹©ä¸€ä¸ªé€‰é¡¹ï¼š
-> é€‰é¡¹1 #tag1
-> é€‰é¡¹2 <<if $hp > 50>> #tag2
===";

            var tokens = TokenizeScript(script);
            

            var expectedTokens = new List<(TokenType type, string value)>
            {
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "é€‰æ‹©ä¸€ä¸ªé€‰é¡¹ï¼š"),
                (TokenType.ARROW, "->"),
                (TokenType.TEXT, " é€‰é¡¹1 "),
                (TokenType.HASH, "#"),
                (TokenType.TEXT, "tag1"),
                (TokenType.ARROW, "->"),
                (TokenType.TEXT, " é€‰é¡¹2 "),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.IF, "if"),
                (TokenType.VARIABLE, "hp"),
                (TokenType.GREATER, ">"),
                (TokenType.NUMBER, "50"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, " "),
                (TokenType.HASH, "#"),
                (TokenType.TEXT, "tag2"),
                (TokenType.NODE_END, "===")
            };

            AssertTokens(tokens, expectedTokens.ToArray());
        }

        [Test]
        public void TestConditions()
        {
            string script = @"---
<<if $hp > 0>>
ä½ è¿˜æ´»ç€
<<elif $hp == 0>>
ä½ æ­»äº†
<<else>>
çŠ¶æ€æœªçŸ¥
<<endif>>
===";

            var tokens = TokenizeScript(script);

            var expectedTokens = new List<(TokenType type, string value)>
            {
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.IF, "if"),
                (TokenType.VARIABLE, "hp"),
                (TokenType.GREATER, ">"),
                (TokenType.NUMBER, "0"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, "ä½ è¿˜æ´»ç€"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.ELIF, "elif"),
                (TokenType.VARIABLE, "hp"),
                (TokenType.EQUALS, "=="),
                (TokenType.NUMBER, "0"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, "ä½ æ­»äº†"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.ELSE, "else"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, "çŠ¶æ€æœªçŸ¥"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.ENDIF, "endif"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            };

            AssertTokens(tokens, expectedTokens.ToArray());
        }

        [Test]
        public void TestStringLiterals()
        {
            string script = @"---
<<set $message = ""Hello World"">>
<<set $name = 'John Doe'>>
===";

            var tokens = TokenizeScript(script);

            var expectedTokens = new List<(TokenType type, string value)>
            {
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "message"),
                (TokenType.ASSIGN, "="),
                (TokenType.QUOTE, "\""),
                (TokenType.TEXT, "Hello World"),
                (TokenType.QUOTE, "\""),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "name"),
                (TokenType.ASSIGN, "="),
                (TokenType.QUOTE, "'"),
                (TokenType.TEXT, "John Doe"),
                (TokenType.QUOTE, "'"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            };

            AssertTokens(tokens, expectedTokens.ToArray());
        }

        [Test]
        public void TestStringWithInterpolation()
        {
            string script = @"---
<<set $greeting = ""Hello {$name}, welcome to {$place}!"">>
===";

            var tokens = TokenizeScript(script);

            var expectedTokens = new List<(TokenType type, string value)>
            {
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "greeting"),
                (TokenType.ASSIGN, "="),
                (TokenType.QUOTE, "\""),
                (TokenType.TEXT, "Hello "),
                (TokenType.LEFT_BRACE, "{"),
                (TokenType.VARIABLE, "name"),
                (TokenType.RIGHT_BRACE, "}"),
                (TokenType.TEXT, ", welcome to "),
                (TokenType.LEFT_BRACE, "{"),
                (TokenType.VARIABLE, "place"),
                (TokenType.RIGHT_BRACE, "}"),
                (TokenType.TEXT, "!"),
                (TokenType.QUOTE, "\""),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            };

            AssertTokens(tokens, expectedTokens.ToArray());
        }

        [Test]
        public void TestOperators()
        {
            string script = @"---
<<if $a + $b * $c >= $d && $e or not $f>>
æµ‹è¯•
<<endif>>
===";

            var tokens = TokenizeScript(script);

            var expectedTokens = new List<(TokenType type, string value)>
            {
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.IF, "if"),
                (TokenType.VARIABLE, "a"),
                (TokenType.PLUS, "+"),
                (TokenType.VARIABLE, "b"),
                (TokenType.MULTIPLY, "*"),
                (TokenType.VARIABLE, "c"),
                (TokenType.GREATER_EQUALS, ">="),
                (TokenType.VARIABLE, "d"),
                (TokenType.AND, "&&"),
                (TokenType.VARIABLE, "e"),
                (TokenType.OR, "or"),
                (TokenType.NOT, "not"),
                (TokenType.VARIABLE, "f"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, "æµ‹è¯•"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.ENDIF, "endif"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            };

            AssertTokens(tokens, expectedTokens.ToArray());
        }

        [Test]
        public void TestFunctionCalls()
        {
            string script = @"---
<<if visited(""node1"") && random(0, 10) > 5>>
æµ‹è¯•å‡½æ•°è°ƒç”¨
<<endif>>
===";

            var tokens = TokenizeScript(script);

            var expectedTokens = new List<(TokenType type, string value)>
            {
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.IF, "if"),
                (TokenType.IDENTIFIER, "visited"),
                (TokenType.LEFT_PAREN, "("),
                (TokenType.QUOTE, "\""),
                (TokenType.TEXT, "node1"),
                (TokenType.QUOTE, "\""),
                (TokenType.RIGHT_PAREN, ")"),
                (TokenType.AND, "&&"),
                (TokenType.IDENTIFIER, "random"),
                (TokenType.LEFT_PAREN, "("),
                (TokenType.NUMBER, "0"),
                (TokenType.COMMA, ","),
                (TokenType.NUMBER, "10"),
                (TokenType.RIGHT_PAREN, ")"),
                (TokenType.GREATER, ">"),
                (TokenType.NUMBER, "5"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, "æµ‹è¯•å‡½æ•°è°ƒç”¨"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.ENDIF, "endif"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            };

            AssertTokens(tokens, expectedTokens.ToArray());
        }

        [Test]
        public void TestNarrationWithColon()
        {
            string script = @"---
:è¿™æ˜¯å†’å·æ—ç™½æ–‡æœ¬
æ™®é€šæ—ç™½æ–‡æœ¬
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.COLON, ":"),
                (TokenType.TEXT, "è¿™æ˜¯å†’å·æ—ç™½æ–‡æœ¬"),
                (TokenType.TEXT, "æ™®é€šæ—ç™½æ–‡æœ¬"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestComments()
        {
            string script = @"// è¿™æ˜¯æ³¨é‡Š
node: test
---
// è¿™æ˜¯å¦ä¸€ä¸ªæ³¨é‡Š
è§’è‰²: å¯¹è¯å†…å®¹
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.IDENTIFIER, "node"),
                (TokenType.METADATA_SEPARATOR, ":"),
                (TokenType.TEXT, "test"),
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "è§’è‰²"),
                (TokenType.COLON, ":"),
                (TokenType.TEXT, " å¯¹è¯å†…å®¹"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestEscapedCharacters()
        {
            string script = @"---
è§’è‰²: è¿™æ˜¯\:è½¬ä¹‰å†’å·ï¼Œè¿™æ˜¯\#è½¬ä¹‰æ ‡ç­¾ï¼Œè¿™æ˜¯\\è½¬ä¹‰åæ–œæ 
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "è§’è‰²"),
                (TokenType.COLON, ":"),
                (TokenType.TEXT, " è¿™æ˜¯:è½¬ä¹‰å†’å·ï¼Œè¿™æ˜¯#è½¬ä¹‰æ ‡ç­¾ï¼Œè¿™æ˜¯\\è½¬ä¹‰åæ–œæ "),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestComplexExpression()
        {
            string script = @"---
<<set $result = ($a + $b) * ($c - $d) / (2 + 3.14)>>
===";

            var tokens = TokenizeScript(script);

            var expectedTokens = new List<(TokenType type, string value)>
            {
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "result"),
                (TokenType.ASSIGN, "="),
                (TokenType.LEFT_PAREN, "("),
                (TokenType.VARIABLE, "a"),
                (TokenType.PLUS, "+"),
                (TokenType.VARIABLE, "b"),
                (TokenType.RIGHT_PAREN, ")"),
                (TokenType.MULTIPLY, "*"),
                (TokenType.LEFT_PAREN, "("),
                (TokenType.VARIABLE, "c"),
                (TokenType.MINUS, "-"),
                (TokenType.VARIABLE, "d"),
                (TokenType.RIGHT_PAREN, ")"),
                (TokenType.DIVIDE, "/"),
                (TokenType.LEFT_PAREN, "("),
                (TokenType.NUMBER, "2"),
                (TokenType.PLUS, "+"),
                (TokenType.NUMBER, "3.14"),
                (TokenType.RIGHT_PAREN, ")"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            };

            AssertTokens(tokens, expectedTokens.ToArray());
        }

        [Test]
        public void TestBooleanLiterals()
        {
            string script = @"---
<<set $isAlive = true>>
<<set $isDead = false>>
===";

            var tokens = TokenizeScript(script);

            var expectedTokens = new List<(TokenType type, string value)>
            {
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "isAlive"),
                (TokenType.ASSIGN, "="),
                (TokenType.TRUE, "true"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "isDead"),
                (TokenType.ASSIGN, "="),
                (TokenType.FALSE, "false"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            };

            AssertTokens(tokens, expectedTokens.ToArray());
        }

        [Test]
        public void TestMultipleNodes()
        {
            string script = @"node: first
---
ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
===

node: second  
---
ç¬¬äºŒä¸ªèŠ‚ç‚¹
===";

            var tokens = TokenizeScript(script);

            var expectedTokens = new List<(TokenType type, string value)>
            {
                (TokenType.IDENTIFIER, "node"),
                (TokenType.METADATA_SEPARATOR, ":"),
                (TokenType.TEXT, "first"),
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "ç¬¬ä¸€ä¸ªèŠ‚ç‚¹"),
                (TokenType.NODE_END, "==="),
                (TokenType.IDENTIFIER, "node"),
                (TokenType.METADATA_SEPARATOR, ":"),
                (TokenType.TEXT, "second"),
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "ç¬¬äºŒä¸ªèŠ‚ç‚¹"),
                (TokenType.NODE_END, "===")
            };

            AssertTokens(tokens, expectedTokens.ToArray());
        }

        [Test]
        public void TestIndentationTokens()
        {
            string script = @"---
-> é€‰é¡¹1
    åµŒå¥—å†…å®¹1
    åµŒå¥—å†…å®¹2
-> é€‰é¡¹2
===";

            var tokens = TokenizeScript(script);

            // è¿™ä¸ªæµ‹è¯•ä¸“é—¨æ£€æŸ¥ç¼©è¿›Token
            var indentTokens = tokens.Where(t => t.Type == TokenType.INDENT || t.Type == TokenType.DEDENT).ToList();

            // åº”è¯¥æœ‰ä¸€ä¸ªINDENTå’Œä¸€ä¸ªDEDENT
            Assert.AreEqual(2, indentTokens.Count, "åº”è¯¥æœ‰2ä¸ªç¼©è¿›ç›¸å…³çš„Token");
            Assert.AreEqual(TokenType.INDENT, indentTokens[0].Type, "ç¬¬ä¸€ä¸ªåº”è¯¥æ˜¯INDENT");
            Assert.AreEqual(TokenType.DEDENT, indentTokens[1].Type, "ç¬¬äºŒä¸ªåº”è¯¥æ˜¯DEDENT");
        }

        [Test]
        public void TestEmptyScript()
        {
            string script = "";

            var tokens = TokenizeScript(script);

            Assert.AreEqual(1, tokens.Count, "ç©ºè„šæœ¬åº”è¯¥åªæœ‰EOF Token");
            Assert.AreEqual(TokenType.EOF, tokens[0].Type, "åº”è¯¥æ˜¯EOF Token");
        }

        [Test]
        public void TestOnlyComments()
        {
            string script = @"// åªæœ‰æ³¨é‡Šçš„è„šæœ¬
// å¦ä¸€è¡Œæ³¨é‡Š";

            var tokens = TokenizeScript(script);

            Assert.AreEqual(1, tokens.Count, "åªæœ‰æ³¨é‡Šçš„è„šæœ¬åº”è¯¥åªæœ‰EOF Token");
            Assert.AreEqual(TokenType.EOF, tokens[0].Type, "åº”è¯¥æ˜¯EOF Token");
        }

        [Test]
        public void TestMixedIndentationWarning()
        {
            string script = @"---
-> é€‰é¡¹1
	    åµŒå¥—å†…å®¹ï¼ˆæ··åˆTabå’Œç©ºæ ¼ï¼‰
===";

            // è¿™ä¸ªæµ‹è¯•ä¸»è¦æ˜¯éªŒè¯ä¸ä¼šå› ä¸ºæ··åˆç¼©è¿›è€Œå´©æºƒ
            var tokens = TokenizeScript(script);
            Assert.IsNotNull(tokens, "æ··åˆç¼©è¿›æ—¶åº”è¯¥ä»èƒ½æ­£å¸¸è§£æ");
            Assert.IsTrue(tokens.Any(t => t.Type == TokenType.NODE_START), "åº”è¯¥åŒ…å«èŠ‚ç‚¹å¼€å§‹æ ‡è®°");
        }

        [Test]
        public void TestExtremeLongText()
        {
            var longText = new string('æµ‹', 1000);
            string script = $@"---
è§’è‰²: {longText}
===";

            var tokens = TokenizeScript(script);
            
            var textToken = tokens.FirstOrDefault(t => t.Type == TokenType.TEXT && t.Value.Contains("æµ‹"));
            Assert.IsNotNull(textToken, "åº”è¯¥èƒ½å¤„ç†æé•¿æ–‡æœ¬");
            Assert.AreEqual($" {longText}", textToken.Value, "é•¿æ–‡æœ¬å†…å®¹åº”è¯¥æ­£ç¡®");
        }

        [Test]
        public void TestUnicodeEmojis()
        {
            string script = @"---
è§’è‰²: ä½ å¥½ä¸–ç•Œ ğŸ˜ŠğŸŒŸğŸ® Unicodeæµ‹è¯•
===";

            var tokens = TokenizeScript(script);
            
            var textToken = tokens.FirstOrDefault(t => t.Type == TokenType.TEXT && t.Value.Contains("ğŸ˜Š"));
            Assert.IsNotNull(textToken, "åº”è¯¥èƒ½å¤„ç†Unicodeè¡¨æƒ…ç¬¦å·");
            Assert.IsTrue(textToken.Value.Contains("ğŸ˜ŠğŸŒŸğŸ®"), "åº”è¯¥æ­£ç¡®ä¿ç•™æ‰€æœ‰è¡¨æƒ…ç¬¦å·");
        }

        [Test]
        public void TestNestedQuotesAndEscaping()
        {
            string script = @"---
<<set $msg = ""å¤–å±‚å¼•å·'å†…å±‚å•å¼•å·'å’Œ\""è½¬ä¹‰åŒå¼•å·\""å’Œ\\åæ–œæ "">>
===";

            var tokens = TokenizeScript(script);

            var textTokens = tokens.Where(t => t.Type == TokenType.TEXT).ToList();
            var combinedText = string.Join("", textTokens.Select(t => t.Value));
            Assert.IsTrue(combinedText.Contains("'å†…å±‚å•å¼•å·'"), "åº”è¯¥æ­£ç¡®å¤„ç†åµŒå¥—çš„å•å¼•å·");
            Assert.IsTrue(combinedText.Contains("\"è½¬ä¹‰åŒå¼•å·\""), "åº”è¯¥æ­£ç¡®å¤„ç†è½¬ä¹‰çš„åŒå¼•å·");
            Assert.IsTrue(combinedText.Contains("\\åæ–œæ "), "åº”è¯¥æ­£ç¡®å¤„ç†è½¬ä¹‰çš„åæ–œæ ");
        }

        [Test]
        public void TestComplexInterpolationNesting()
        {
            string script = @"---
è§’è‰²: {$name}è¯´ï¼š{$greeting}ï¼Œä»Šå¤©æ˜¯{$date}ï¼Œå¿ƒæƒ…{$mood}ï¼
===";

            var tokens = TokenizeScript(script);

            var braceTokens = tokens.Where(t => t.Type == TokenType.LEFT_BRACE || t.Type == TokenType.RIGHT_BRACE).ToList();
            Assert.AreEqual(8, braceTokens.Count, "åº”è¯¥æœ‰8ä¸ªå¤§æ‹¬å·ï¼ˆ4å¯¹ï¼‰");

            var variableTokens = tokens.Where(t => t.Type == TokenType.VARIABLE).ToList();
            Assert.AreEqual(4, variableTokens.Count, "åº”è¯¥æœ‰4ä¸ªå˜é‡");
            
            var expectedVars = new[] { "name", "greeting", "date", "mood" };
            for (int i = 0; i < expectedVars.Length; i++)
            {
                Assert.AreEqual(expectedVars[i], variableTokens[i].Value, $"ç¬¬{i+1}ä¸ªå˜é‡åº”è¯¥æ˜¯{expectedVars[i]}");
            }
        }

        [Test]
        public void TestEdgeCaseOperators()
        {
            string script = @"---
<<if $a===$b||$c>==$d&&!$e!==$f>>
æµ‹è¯•
<<endif>>
===";

            var tokens = TokenizeScript(script);

            // æ£€æŸ¥è¿ç»­æ“ä½œç¬¦çš„å¤„ç†
            var operatorTokens = tokens.Where(t => 
                t.Type == TokenType.EQUALS || t.Type == TokenType.NOT_EQUALS || 
                t.Type == TokenType.GREATER_EQUALS || t.Type == TokenType.OR || 
                t.Type == TokenType.AND || t.Type == TokenType.NOT).ToList();

            Assert.IsTrue(operatorTokens.Count >= 6, "åº”è¯¥è¯†åˆ«å‡ºå¤šä¸ªæ“ä½œç¬¦");
        }

        [Test]
        public void TestCommandBoundaries()
        {
            string script = @"---
<<set $a=1>><<wait 2>><<jump next>>
===";

            var tokens = TokenizeScript(script);

            var commandStarts = tokens.Where(t => t.Type == TokenType.COMMAND_START).ToList();
            var commandEnds = tokens.Where(t => t.Type == TokenType.COMMAND_END).ToList();
            
            Assert.AreEqual(3, commandStarts.Count, "åº”è¯¥æœ‰3ä¸ªå‘½ä»¤å¼€å§‹æ ‡è®°");
            Assert.AreEqual(3, commandEnds.Count, "åº”è¯¥æœ‰3ä¸ªå‘½ä»¤ç»“æŸæ ‡è®°");
        }

        [Test]
        public void TestNumberFormats()
        {
            string script = @"---
<<set $int = 42>>
<<set $float = 3.14>>
<<set $zero = 0>>
<<set $negative = -123>>
<<set $decimal = 0.001>>
===";

            var tokens = TokenizeScript(script);

            var numberTokens = tokens.Where(t => t.Type == TokenType.NUMBER).ToList();
            var expectedNumbers = new[] { "42", "3.14", "0", "123", "0.001" }; // æ³¨æ„-123ä¸­çš„123éƒ¨åˆ†

            Assert.AreEqual(5, numberTokens.Count, "åº”è¯¥è¯†åˆ«å‡º5ä¸ªæ•°å­—");
            
            for (int i = 0; i < expectedNumbers.Length; i++)
            {
                Assert.AreEqual(expectedNumbers[i], numberTokens[i].Value, $"ç¬¬{i+1}ä¸ªæ•°å­—åº”è¯¥æ˜¯{expectedNumbers[i]}");
            }
        }

        [Test]
        public void TestMaxDepthIndentation()
        {
            string script = @"---
-> å±‚çº§1
    -> å±‚çº§2
        -> å±‚çº§3
            -> å±‚çº§4
                -> å±‚çº§5
                    æ–‡æœ¬å†…å®¹
===";

            var tokens = TokenizeScript(script);

            var indentTokens = tokens.Where(t => t.Type == TokenType.INDENT).ToList();
            var dedentTokens = tokens.Where(t => t.Type == TokenType.DEDENT).ToList();

            Assert.IsTrue(indentTokens.Count > 0, "åº”è¯¥æœ‰ç¼©è¿›Token");
            Assert.IsTrue(dedentTokens.Count > 0, "åº”è¯¥æœ‰åç¼©è¿›Token");
        }

        [Test]
        public void TestStringModeTransitions()
        {
            string script = @"---
<<set $s1 = ""å•å¼•å·'å†…å®¹'"">>
<<set $s2 = 'åŒå¼•å·""å†…å®¹""'>>
<<set $s3 = ""æ’å€¼{$var}å†…å®¹"">>
===";

            var tokens = TokenizeScript(script);

            var quoteTokens = tokens.Where(t => t.Type == TokenType.QUOTE).ToList();
            Assert.AreEqual(6, quoteTokens.Count, "åº”è¯¥æœ‰6ä¸ªå¼•å·Token");

            // éªŒè¯å¼•å·ç±»å‹é…å¯¹
            Assert.AreEqual("\"", quoteTokens[0].Value, "ç¬¬1ä¸ªå¼•å·åº”è¯¥æ˜¯åŒå¼•å·");
            Assert.AreEqual("\"", quoteTokens[1].Value, "ç¬¬2ä¸ªå¼•å·åº”è¯¥æ˜¯åŒå¼•å·");
            Assert.AreEqual("'", quoteTokens[2].Value, "ç¬¬3ä¸ªå¼•å·åº”è¯¥æ˜¯å•å¼•å·");
            Assert.AreEqual("'", quoteTokens[3].Value, "ç¬¬4ä¸ªå¼•å·åº”è¯¥æ˜¯å•å¼•å·");
        }

        [Test]
        public void TestMetadataEdgeCases()
        {
            string script = @"node: test_node
empty_key: 
key_with_spaces: value with spaces
unicode_key: ğŸŒŸæµ‹è¯•å€¼ğŸŒŸ
---
å†…å®¹
===";

            var tokens = TokenizeScript(script);

            var identifierTokens = tokens.Where(t => t.Type == TokenType.IDENTIFIER).ToList();
            var separatorTokens = tokens.Where(t => t.Type == TokenType.METADATA_SEPARATOR).ToList();

            Assert.AreEqual(4, separatorTokens.Count, "åº”è¯¥æœ‰4ä¸ªå…ƒæ•°æ®åˆ†éš”ç¬¦");
            Assert.IsTrue(identifierTokens.Any(t => t.Value == "unicode_key"), "åº”è¯¥èƒ½å¤„ç†Unicodeé”®å");
        }

        [Test]
        public void TestWindowsLineEndings()
        {
            string script = "node: test\r\n---\r\nè§’è‰²: å¯¹è¯\r\n===";

            var tokens = TokenizeScript(script);

            var newlineTokens = tokens.Where(t => t.Type == TokenType.NEWLINE).ToList();
            Assert.IsTrue(newlineTokens.Count > 0, "åº”è¯¥æ­£ç¡®å¤„ç†Windowsæ¢è¡Œç¬¦");
        }

        [Test]
        public void TestMacLineEndings()
        {
            string script = "node: test\r---\rè§’è‰²: å¯¹è¯\r===";

            var tokens = TokenizeScript(script);

            var newlineTokens = tokens.Where(t => t.Type == TokenType.NEWLINE).ToList();
            Assert.IsTrue(newlineTokens.Count > 0, "åº”è¯¥æ­£ç¡®å¤„ç†Macæ¢è¡Œç¬¦");
        }

        [Test]
        public void TestColonEdgeCases()
        {
            string script = @"---
:æ—ç™½å†’å·å¼€å¤´
è§’è‰²å: å¯¹è¯å†…å®¹
æ™®é€š:æ–‡æœ¬:ä¸­é—´:æœ‰:å†’å·
===";

            var tokens = TokenizeScript(script);

            var colonTokens = tokens.Where(t => t.Type == TokenType.COLON).ToList();
            Assert.IsTrue(colonTokens.Count >= 2, "åº”è¯¥è¯†åˆ«å‡ºå¤šä¸ªå†’å·");
        }

        [Test]
        public void TestArrowInText()
        {
            string script = @"---
æ™®é€šæ–‡æœ¬ -> ä¸æ˜¯é€‰é¡¹ç®­å¤´
-> çœŸæ­£çš„é€‰é¡¹
===";

            var tokens = TokenizeScript(script);

            var arrowTokens = tokens.Where(t => t.Type == TokenType.ARROW).ToList();
            Assert.AreEqual(1, arrowTokens.Count, "åº”è¯¥åªè¯†åˆ«ä¸€ä¸ªçœŸæ­£çš„ç®­å¤´ï¼ˆåœ¨è¡Œé¦–çš„ï¼‰");

            var textTokens = tokens.Where(t => t.Type == TokenType.TEXT).ToList();
            var arrowInText = textTokens.Any(t => t.Value.Contains("->"));
            Assert.IsTrue(arrowInText, "æ–‡æœ¬ä¸­çš„ç®­å¤´åº”è¯¥ä½œä¸ºæ™®é€šæ–‡æœ¬å¤„ç†");
        }

        [Test]
        public void TestHashInText()
        {
            string script = @"---
è§’è‰²: è¿™æ˜¯\#å·åœ¨æ–‡æœ¬ä¸­çš„æƒ…å†µ #real_tag
===";

            var tokens = TokenizeScript(script);

            var hashTokens = tokens.Where(t => t.Type == TokenType.HASH).ToList();
            var textTokens = tokens.Where(t => t.Type == TokenType.TEXT).ToList();

            Assert.IsTrue(textTokens.Any(t => t.Value.Contains("#å·")), "æ–‡æœ¬ä¸­çš„#å·åº”è¯¥è¢«åŒ…å«åœ¨æ–‡æœ¬ä¸­");
            Assert.IsTrue(hashTokens.Count >= 1, "ç‹¬ç«‹çš„#æ ‡ç­¾åº”è¯¥è¢«è¯†åˆ«");
        }

        [Test]
        public void TestBracketEdgeCases()
        {
            string script = @"---
è§’è‰²: æ–¹æ‹¬å·[text]å’Œåœ†æ‹¬å·(text)å’ŒèŠ±æ‹¬å·{$var}
===";

            var tokens = TokenizeScript(script);

            var braceTokens = tokens.Where(t => t.Type == TokenType.LEFT_BRACE || t.Type == TokenType.RIGHT_BRACE).ToList();
            Assert.AreEqual(2, braceTokens.Count, "åº”è¯¥åªè¯†åˆ«æ’å€¼çš„èŠ±æ‹¬å·");

            var textTokens = tokens.Where(t => t.Type == TokenType.TEXT).ToList();
            Assert.IsTrue(textTokens.Any(t => t.Value.Contains("[text]")), "æ–¹æ‹¬å·åº”è¯¥ä½œä¸ºæ™®é€šæ–‡æœ¬");
            Assert.IsTrue(textTokens.Any(t => t.Value.Contains("(text)")), "åœ†æ‹¬å·åº”è¯¥ä½œä¸ºæ™®é€šæ–‡æœ¬");
        }

        [Test]
        public void TestUnterminatedString()
        {
            string script = @"---
<<set $msg = ""æœªç»“æŸçš„å­—ç¬¦ä¸²
===";

            // è¿™ä¸ªæµ‹è¯•ä¸»è¦ç¡®ä¿ä¸ä¼šå› ä¸ºæœªç»“æŸçš„å­—ç¬¦ä¸²è€Œå´©æºƒ
            var tokens = TokenizeScript(script);
            Assert.IsNotNull(tokens, "æœªç»“æŸçš„å­—ç¬¦ä¸²ä¸åº”å¯¼è‡´å´©æºƒ");
            Assert.IsTrue(tokens.Any(t => t.Type == TokenType.EOF), "åº”è¯¥èƒ½åˆ°è¾¾EOF");
        }

        [Test]
        public void TestEmptyInterpolation()
        {
            string script = @"---
è§’è‰²: ç©ºæ’å€¼{}æµ‹è¯•
===";

            var tokens = TokenizeScript(script);

            var braceTokens = tokens.Where(t => t.Type == TokenType.LEFT_BRACE || t.Type == TokenType.RIGHT_BRACE).ToList();
            Assert.AreEqual(2, braceTokens.Count, "åº”è¯¥è¯†åˆ«ç©ºæ’å€¼çš„æ‹¬å·");
        }

        [Test]
        public void TestSpecialCharactersInIdentifiers()
        {
            string script = @"test_node_123: value
node_æµ‹è¯•: ä¸­æ–‡å€¼
---
å†…å®¹
===";

            var tokens = TokenizeScript(script);

            var identifiers = tokens.Where(t => t.Type == TokenType.IDENTIFIER).ToList();
            Assert.IsTrue(identifiers.Any(t => t.Value == "test_node_123"), "åº”è¯¥æ”¯æŒä¸‹åˆ’çº¿å’Œæ•°å­—çš„æ ‡è¯†ç¬¦");
            Assert.IsTrue(identifiers.Any(t => t.Value == "node_æµ‹è¯•"), "åº”è¯¥æ”¯æŒä¸­æ–‡å­—ç¬¦çš„æ ‡è¯†ç¬¦");
        }
    }
}
