using System;
using System.Collections.Generic;
using System.Linq;
using NUnit.Framework;
using UnityEngine;

namespace MookDialogueScript.Tests
{
    /// <summary>
    /// è¯æ³•åˆ†æå™¨æµ‹è¯• - å…¨é¢çš„è¾¹ç•Œæµ‹è¯•å’Œå¼‚å¸¸æƒ…å†µå¤„ç†
    /// </summary>
    public class LexerTests
    {
        /// <summary>
        /// åˆ›å»ºè¯æ³•åˆ†æå™¨å¹¶è·å–Tokenåˆ—è¡¨
        /// </summary>
        private List<Token> TokenizeScript(string script)
        {
            var lexer = new Lexer(script);
            var tokens = lexer.Tokenize();
            foreach (var token in tokens)
            {
                Debug.Log($"Token: {token.Type} '{token.Value}' at {token.Line}:{token.Column}");
            }
            return tokens;
        }

        /// <summary>
        /// éªŒè¯Tokenåºåˆ—ï¼ˆåŒ…å«è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼‰
        /// </summary>
        private void AssertTokens(List<Token> tokens, params (TokenType type, string value)[] expectedTokens)
        {
            // è¿‡æ»¤æ‰NEWLINE tokenä»¥ç®€åŒ–æµ‹è¯•
            var filteredTokens = tokens.Where(t => t.Type != TokenType.NEWLINE).ToList();

            var errorMessage = "Tokenæ•°é‡ä¸åŒ¹é…ï¼ˆåŒ…æ‹¬EOFï¼‰" + System.Environment.NewLine +
                "å®é™…Token: " + string.Join(", ", filteredTokens.Select(t => t.Type + "('" + t.Value + "')")) + System.Environment.NewLine +
                "æœŸæœ›Token: " + string.Join(", ", expectedTokens.Select(e => e.type + "('" + e.value + "')")) + " + EOF";
            
            Assert.AreEqual(expectedTokens.Length + 1, filteredTokens.Count, errorMessage);

            for (int i = 0; i < expectedTokens.Length; i++)
            {
                var expected = expectedTokens[i];
                var actual = filteredTokens[i];
                Assert.AreEqual(expected.type, actual.Type, $"ç¬¬{i+1}ä¸ªTokenç±»å‹ä¸åŒ¹é…\næœŸæœ›: {expected.type}\nå®é™…: {actual.Type}\nTokenå€¼: '{actual.Value}'");
                Assert.AreEqual(expected.value, actual.Value, $"ç¬¬{i+1}ä¸ªTokenå€¼ä¸åŒ¹é…\næœŸæœ›: '{expected.value}'\nå®é™…: '{actual.Value}'\nTokenç±»å‹: {actual.Type}");
            }

            // æœ€åä¸€ä¸ªåº”è¯¥æ˜¯EOF
            Assert.AreEqual(TokenType.EOF, filteredTokens.Last().Type, "æœ€åä¸€ä¸ªTokenåº”è¯¥æ˜¯EOF");
        }

        /// <summary>
        /// éªŒè¯Tokenåºåˆ—ï¼ˆåŒ…å«è¡Œåˆ—ä½ç½®ä¿¡æ¯ï¼‰
        /// </summary>
        private void AssertTokensWithPosition(List<Token> tokens, params (TokenType type, string value, int line, int column)[] expectedTokens)
        {
            var filteredTokens = tokens.Where(t => t.Type != TokenType.NEWLINE).ToList();

            for (int i = 0; i < Math.Min(expectedTokens.Length, filteredTokens.Count); i++)
            {
                var expected = expectedTokens[i];
                var actual = filteredTokens[i];
                Assert.AreEqual(expected.type, actual.Type, $"ç¬¬{i+1}ä¸ªTokenç±»å‹ä¸åŒ¹é…");
                Assert.AreEqual(expected.value, actual.Value, $"ç¬¬{i+1}ä¸ªTokenå€¼ä¸åŒ¹é…");
                Assert.AreEqual(expected.line, actual.Line, $"ç¬¬{i+1}ä¸ªTokenè¡Œå·ä¸åŒ¹é…");
                Assert.AreEqual(expected.column, actual.Column, $"ç¬¬{i+1}ä¸ªTokenåˆ—å·ä¸åŒ¹é…");
            }
        }

        // === åŸºç¡€è¯­æ³•æµ‹è¯• ===
        [Test]
        public void TestBasicNodeStructure()
        {
            string script = @"node: test
---
è§’è‰²: ä½ å¥½ä¸–ç•Œ
===";

            var tokens = TokenizeScript(script);
            
            AssertTokens(tokens,
                (TokenType.IDENTIFIER, "node"),
                (TokenType.METADATA_SEPARATOR, ":"),
                (TokenType.TEXT, "test"),
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "è§’è‰²"),
                (TokenType.COLON, ":"),
                (TokenType.TEXT, " ä½ å¥½ä¸–ç•Œ"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestVariableInterpolation()
        {
            string script = @"---
è§’è‰²: ä½ å¥½{$name}ï¼Œæ¬¢è¿æ¥åˆ°{$place}
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "è§’è‰²"),
                (TokenType.COLON, ":"),
                (TokenType.TEXT, " ä½ å¥½"),
                (TokenType.LEFT_BRACE, "{"),
                (TokenType.VARIABLE, "name"),
                (TokenType.RIGHT_BRACE, "}"),
                (TokenType.TEXT, "ï¼Œæ¬¢è¿æ¥åˆ°"),
                (TokenType.LEFT_BRACE, "{"),
                (TokenType.VARIABLE, "place"),
                (TokenType.RIGHT_BRACE, "}"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestBasicCommands()
        {
            string script = @"---
<<set $hp = 100>>
<<var $gold 50>>
<<wait 2.0>>
<<jump ending>>
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "hp"),
                (TokenType.ASSIGN, "="),
                (TokenType.NUMBER, "100"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.VAR, "var"),
                (TokenType.VARIABLE, "gold"),
                (TokenType.NUMBER, "50"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.WAIT, "wait"),
                (TokenType.NUMBER, "2.0"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.JUMP, "jump"),
                (TokenType.IDENTIFIER, "ending"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestChoiceOptions()
        {
            string script = @"---
é€‰æ‹©ä¸€ä¸ªé€‰é¡¹ï¼š
-> é€‰é¡¹1 #tag1
-> é€‰é¡¹2 <<if $hp > 50>> #tag2
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "é€‰æ‹©ä¸€ä¸ªé€‰é¡¹ï¼š"),
                (TokenType.ARROW, "->"),
                (TokenType.TEXT, " é€‰é¡¹1 "),
                (TokenType.HASH, "#"),
                (TokenType.TEXT, "tag1"),
                (TokenType.ARROW, "->"),
                (TokenType.TEXT, " é€‰é¡¹2 "),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.IF, "if"),
                (TokenType.VARIABLE, "hp"),
                (TokenType.GREATER, ">"),
                (TokenType.NUMBER, "50"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, " "),
                (TokenType.HASH, "#"),
                (TokenType.TEXT, "tag2"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestConditionalBlocks()
        {
            string script = @"---
<<if $hp > 0>>
ä½ è¿˜æ´»ç€
<<elif $hp == 0>>
ä½ æ­»äº†
<<else>>
çŠ¶æ€æœªçŸ¥
<<endif>>
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.IF, "if"),
                (TokenType.VARIABLE, "hp"),
                (TokenType.GREATER, ">"),
                (TokenType.NUMBER, "0"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, "ä½ è¿˜æ´»ç€"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.ELIF, "elif"),
                (TokenType.VARIABLE, "hp"),
                (TokenType.EQUALS, "=="),
                (TokenType.NUMBER, "0"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, "ä½ æ­»äº†"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.ELSE, "else"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, "çŠ¶æ€æœªçŸ¥"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.ENDIF, "endif"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            );
        }

        // === å­—ç¬¦ä¸²ä¸æ•°å€¼æµ‹è¯• ===
        [Test]
        public void TestStringLiterals()
        {
            string script = @"---
<<set $message = ""Hello World"">>
<<set $name = 'John Doe'>>
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "message"),
                (TokenType.ASSIGN, "="),
                (TokenType.QUOTE, "\""),
                (TokenType.TEXT, "Hello World"),
                (TokenType.QUOTE, "\""),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "name"),
                (TokenType.ASSIGN, "="),
                (TokenType.QUOTE, "'"),
                (TokenType.TEXT, "John Doe"),
                (TokenType.QUOTE, "'"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestStringWithInterpolation()
        {
            string script = @"---
<<set $greeting = ""Hello {$name}, welcome to {$place}!"">>
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "greeting"),
                (TokenType.ASSIGN, "="),
                (TokenType.QUOTE, "\""),
                (TokenType.TEXT, "Hello "),
                (TokenType.LEFT_BRACE, "{"),
                (TokenType.VARIABLE, "name"),
                (TokenType.RIGHT_BRACE, "}"),
                (TokenType.TEXT, ", welcome to "),
                (TokenType.LEFT_BRACE, "{"),
                (TokenType.VARIABLE, "place"),
                (TokenType.RIGHT_BRACE, "}"),
                (TokenType.TEXT, "!"),
                (TokenType.QUOTE, "\""),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            );
        }

        // === è¿ç®—ç¬¦ä¸è¡¨è¾¾å¼æµ‹è¯• ===
        [Test]
        public void TestMathematicalOperators()
        {
            string script = @"---
<<if $a + $b * $c >= $d && $e or not $f>>
æµ‹è¯•
<<endif>>
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.IF, "if"),
                (TokenType.VARIABLE, "a"),
                (TokenType.PLUS, "+"),
                (TokenType.VARIABLE, "b"),
                (TokenType.MULTIPLY, "*"),
                (TokenType.VARIABLE, "c"),
                (TokenType.GREATER_EQUALS, ">="),
                (TokenType.VARIABLE, "d"),
                (TokenType.AND, "&&"),
                (TokenType.VARIABLE, "e"),
                (TokenType.OR, "or"),
                (TokenType.NOT, "not"),
                (TokenType.VARIABLE, "f"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, "æµ‹è¯•"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.ENDIF, "endif"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestFunctionCallSyntax()
        {
            string script = @"---
<<if visited(""node1"") && random(0, 10) > 5>>
æµ‹è¯•å‡½æ•°è°ƒç”¨
<<endif>>
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.IF, "if"),
                (TokenType.IDENTIFIER, "visited"),
                (TokenType.LEFT_PAREN, "("),
                (TokenType.QUOTE, "\""),
                (TokenType.TEXT, "node1"),
                (TokenType.QUOTE, "\""),
                (TokenType.RIGHT_PAREN, ")"),
                (TokenType.AND, "&&"),
                (TokenType.IDENTIFIER, "random"),
                (TokenType.LEFT_PAREN, "("),
                (TokenType.NUMBER, "0"),
                (TokenType.COMMA, ","),
                (TokenType.NUMBER, "10"),
                (TokenType.RIGHT_PAREN, ")"),
                (TokenType.GREATER, ">"),
                (TokenType.NUMBER, "5"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.TEXT, "æµ‹è¯•å‡½æ•°è°ƒç”¨"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.ENDIF, "endif"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            );
        }

        // === ç‰¹æ®Šè¯­æ³•æµ‹è¯• ===
        [Test]
        public void TestNarrationWithColon()
        {
            string script = @"---
:è¿™æ˜¯å†’å·æ—ç™½æ–‡æœ¬
æ™®é€šæ—ç™½æ–‡æœ¬
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.COLON, ":"),
                (TokenType.TEXT, "è¿™æ˜¯å†’å·æ—ç™½æ–‡æœ¬"),
                (TokenType.TEXT, "æ™®é€šæ—ç™½æ–‡æœ¬"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestCommentFiltering()
        {
            string script = @"// è¿™æ˜¯æ³¨é‡Š
node: test
---
// è¿™æ˜¯å¦ä¸€ä¸ªæ³¨é‡Š
è§’è‰²: å¯¹è¯å†…å®¹
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.IDENTIFIER, "node"),
                (TokenType.METADATA_SEPARATOR, ":"),
                (TokenType.TEXT, "test"),
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "è§’è‰²"),
                (TokenType.COLON, ":"),
                (TokenType.TEXT, " å¯¹è¯å†…å®¹"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestEscapeSequences()
        {
            string script = @"---
è§’è‰²: è¿™æ˜¯\:è½¬ä¹‰å†’å·ï¼Œè¿™æ˜¯\#è½¬ä¹‰æ ‡ç­¾ï¼Œè¿™æ˜¯\\è½¬ä¹‰åæ–œæ 
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "è§’è‰²"),
                (TokenType.COLON, ":"),
                (TokenType.TEXT, " è¿™æ˜¯:è½¬ä¹‰å†’å·ï¼Œè¿™æ˜¯#è½¬ä¹‰æ ‡ç­¾ï¼Œè¿™æ˜¯\\è½¬ä¹‰åæ–œæ "),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestComplexMathExpression()
        {
            string script = @"---
<<set $result = ($a + $b) * ($c - $d) / (2 + 3.14)>>
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "result"),
                (TokenType.ASSIGN, "="),
                (TokenType.LEFT_PAREN, "("),
                (TokenType.VARIABLE, "a"),
                (TokenType.PLUS, "+"),
                (TokenType.VARIABLE, "b"),
                (TokenType.RIGHT_PAREN, ")"),
                (TokenType.MULTIPLY, "*"),
                (TokenType.LEFT_PAREN, "("),
                (TokenType.VARIABLE, "c"),
                (TokenType.MINUS, "-"),
                (TokenType.VARIABLE, "d"),
                (TokenType.RIGHT_PAREN, ")"),
                (TokenType.DIVIDE, "/"),
                (TokenType.LEFT_PAREN, "("),
                (TokenType.NUMBER, "2"),
                (TokenType.PLUS, "+"),
                (TokenType.NUMBER, "3.14"),
                (TokenType.RIGHT_PAREN, ")"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            );
        }

        [Test]
        public void TestBooleanLiterals()
        {
            string script = @"---
<<set $isAlive = true>>
<<set $isDead = false>>
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.NODE_START, "---"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "isAlive"),
                (TokenType.ASSIGN, "="),
                (TokenType.TRUE, "true"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.COMMAND_START, "<<"),
                (TokenType.SET, "set"),
                (TokenType.VARIABLE, "isDead"),
                (TokenType.ASSIGN, "="),
                (TokenType.FALSE, "false"),
                (TokenType.COMMAND_END, ">>"),
                (TokenType.NODE_END, "===")
            );
        }

        // === å¤šèŠ‚ç‚¹ç»“æ„æµ‹è¯• ===
        [Test]
        public void TestMultipleNodes()
        {
            string script = @"node: first
---
ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
===

node: second  
---
ç¬¬äºŒä¸ªèŠ‚ç‚¹
===";

            var tokens = TokenizeScript(script);

            AssertTokens(tokens,
                (TokenType.IDENTIFIER, "node"),
                (TokenType.METADATA_SEPARATOR, ":"),
                (TokenType.TEXT, "first"),
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "ç¬¬ä¸€ä¸ªèŠ‚ç‚¹"),
                (TokenType.NODE_END, "==="),
                (TokenType.IDENTIFIER, "node"),
                (TokenType.METADATA_SEPARATOR, ":"),
                (TokenType.TEXT, "second"),
                (TokenType.NODE_START, "---"),
                (TokenType.TEXT, "ç¬¬äºŒä¸ªèŠ‚ç‚¹"),
                (TokenType.NODE_END, "===")
            );
        }

        // === ç¼©è¿›ç»“æ„æµ‹è¯• ===
        [Test]
        public void TestIndentationHandling()
        {
            string script = @"---
-> é€‰é¡¹1
    åµŒå¥—å†…å®¹1
    åµŒå¥—å†…å®¹2
-> é€‰é¡¹2
===";

            var tokens = TokenizeScript(script);

            // æ£€æŸ¥ç¼©è¿›Tokençš„å­˜åœ¨
            var indentTokens = tokens.Where(t => t.Type == TokenType.INDENT || t.Type == TokenType.DEDENT).ToList();

            Assert.AreEqual(2, indentTokens.Count, "åº”è¯¥æœ‰2ä¸ªç¼©è¿›ç›¸å…³çš„Token");
            Assert.AreEqual(TokenType.INDENT, indentTokens[0].Type, "ç¬¬ä¸€ä¸ªåº”è¯¥æ˜¯INDENT");
            Assert.AreEqual(TokenType.DEDENT, indentTokens[1].Type, "ç¬¬äºŒä¸ªåº”è¯¥æ˜¯DEDENT");
        }

        // === è¾¹ç•Œæƒ…å†µæµ‹è¯• ===
        [Test]
        public void TestEmptyScript()
        {
            string script = "";

            var tokens = TokenizeScript(script);

            Assert.AreEqual(1, tokens.Count, "ç©ºè„šæœ¬åº”è¯¥åªæœ‰EOF Token");
            Assert.AreEqual(TokenType.EOF, tokens[0].Type, "åº”è¯¥æ˜¯EOF Token");
        }

        [Test]
        public void TestOnlyComments()
        {
            string script = @"// åªæœ‰æ³¨é‡Šçš„è„šæœ¬
// å¦ä¸€è¡Œæ³¨é‡Š";

            var tokens = TokenizeScript(script);

            Assert.AreEqual(1, tokens.Count, "åªæœ‰æ³¨é‡Šçš„è„šæœ¬åº”è¯¥åªæœ‰EOF Token");
            Assert.AreEqual(TokenType.EOF, tokens[0].Type, "åº”è¯¥æ˜¯EOF Token");
        }

        [Test]
        public void TestMixedIndentationWarning()
        {
            string script = @"---
-> é€‰é¡¹1
	    åµŒå¥—å†…å®¹ï¼ˆæ··åˆTabå’Œç©ºæ ¼ï¼‰
===";

            // è¿™ä¸ªæµ‹è¯•ä¸»è¦æ˜¯éªŒè¯ä¸ä¼šå› ä¸ºæ··åˆç¼©è¿›è€Œå´©æºƒ
            var tokens = TokenizeScript(script);
            Assert.IsNotNull(tokens, "æ··åˆç¼©è¿›æ—¶åº”è¯¥ä»èƒ½æ­£å¸¸è§£æ");
            Assert.IsTrue(tokens.Any(t => t.Type == TokenType.NODE_START), "åº”è¯¥åŒ…å«èŠ‚ç‚¹å¼€å§‹æ ‡è®°");
        }

        [Test]
        public void TestExtremeLongText()
        {
            var longText = new string('æµ‹', 1000);
            string script = $@"---
è§’è‰²: {longText}
===";

            var tokens = TokenizeScript(script);
            
            var textToken = tokens.FirstOrDefault(t => t.Type == TokenType.TEXT && t.Value.Contains("æµ‹"));
            Assert.IsNotNull(textToken, "åº”è¯¥èƒ½å¤„ç†æé•¿æ–‡æœ¬");
            Assert.AreEqual($" {longText}", textToken.Value, "é•¿æ–‡æœ¬å†…å®¹åº”è¯¥æ­£ç¡®");
        }

        [Test]
        public void TestUnicodeEmojis()
        {
            string script = @"---
è§’è‰²: ä½ å¥½ä¸–ç•Œ ğŸ˜ŠğŸŒŸğŸ® Unicodeæµ‹è¯•
===";

            var tokens = TokenizeScript(script);
            
            var textToken = tokens.FirstOrDefault(t => t.Type == TokenType.TEXT && t.Value.Contains("ğŸ˜Š"));
            Assert.IsNotNull(textToken, "åº”è¯¥èƒ½å¤„ç†Unicodeè¡¨æƒ…ç¬¦å·");
            Assert.IsTrue(textToken.Value.Contains("ğŸ˜ŠğŸŒŸğŸ®"), "åº”è¯¥æ­£ç¡®ä¿ç•™æ‰€æœ‰è¡¨æƒ…ç¬¦å·");
        }

        // === å¤æ‚è½¬ä¹‰ä¸åµŒå¥—æµ‹è¯• ===
        [Test]
        public void TestNestedQuotesAndEscaping()
        {
            string script = @"---
<<set $msg = ""å¤–å±‚å¼•å·'å†…å±‚å•å¼•å·'å’Œ\""è½¬ä¹‰åŒå¼•å·\""å’Œ\\åæ–œæ "">>
===";

            var tokens = TokenizeScript(script);

            var textTokens = tokens.Where(t => t.Type == TokenType.TEXT).ToList();
            var combinedText = string.Join("", textTokens.Select(t => t.Value));
            Assert.IsTrue(combinedText.Contains("'å†…å±‚å•å¼•å·'"), "åº”è¯¥æ­£ç¡®å¤„ç†åµŒå¥—çš„å•å¼•å·");
            Assert.IsTrue(combinedText.Contains("\"è½¬ä¹‰åŒå¼•å·\""), "åº”è¯¥æ­£ç¡®å¤„ç†è½¬ä¹‰çš„åŒå¼•å·");
            Assert.IsTrue(combinedText.Contains("\\åæ–œæ "), "åº”è¯¥æ­£ç¡®å¤„ç†è½¬ä¹‰çš„åæ–œæ ");
        }

        [Test]
        public void TestMultipleVariableInterpolation()
        {
            string script = @"---
è§’è‰²: {$name}è¯´ï¼š{$greeting}ï¼Œä»Šå¤©æ˜¯{$date}ï¼Œå¿ƒæƒ…{$mood}ï¼
===";

            var tokens = TokenizeScript(script);

            var braceTokens = tokens.Where(t => t.Type == TokenType.LEFT_BRACE || t.Type == TokenType.RIGHT_BRACE).ToList();
            Assert.AreEqual(8, braceTokens.Count, "åº”è¯¥æœ‰8ä¸ªå¤§æ‹¬å·ï¼ˆ4å¯¹ï¼‰");

            var variableTokens = tokens.Where(t => t.Type == TokenType.VARIABLE).ToList();
            Assert.AreEqual(4, variableTokens.Count, "åº”è¯¥æœ‰4ä¸ªå˜é‡");
            
            var expectedVars = new[] { "name", "greeting", "date", "mood" };
            for (int i = 0; i < expectedVars.Length; i++)
            {
                Assert.AreEqual(expectedVars[i], variableTokens[i].Value, $"ç¬¬{i+1}ä¸ªå˜é‡åº”è¯¥æ˜¯{expectedVars[i]}");
            }
        }

        [Test]
        public void TestConsecutiveOperators()
        {
            string script = @"---
<<if $a===$b||$c>==$d&&!$e!==$f>>
æµ‹è¯•
<<endif>>
===";

            var tokens = TokenizeScript(script);

            // æ£€æŸ¥è¿ç»­æ“ä½œç¬¦çš„å¤„ç†
            var operatorTokens = tokens.Where(t => 
                t.Type == TokenType.EQUALS || t.Type == TokenType.NOT_EQUALS || 
                t.Type == TokenType.GREATER_EQUALS || t.Type == TokenType.OR || 
                t.Type == TokenType.AND || t.Type == TokenType.NOT).ToList();

            Assert.IsTrue(operatorTokens.Count >= 6, "åº”è¯¥è¯†åˆ«å‡ºå¤šä¸ªæ“ä½œç¬¦");
        }

        [Test]
        public void TestConsecutiveCommands()
        {
            string script = @"---
<<set $a=1>><<wait 2>><<jump next>>
===";

            var tokens = TokenizeScript(script);

            var commandStarts = tokens.Where(t => t.Type == TokenType.COMMAND_START).ToList();
            var commandEnds = tokens.Where(t => t.Type == TokenType.COMMAND_END).ToList();
            
            Assert.AreEqual(3, commandStarts.Count, "åº”è¯¥æœ‰3ä¸ªå‘½ä»¤å¼€å§‹æ ‡è®°");
            Assert.AreEqual(3, commandEnds.Count, "åº”è¯¥æœ‰3ä¸ªå‘½ä»¤ç»“æŸæ ‡è®°");
        }

        [Test]
        public void TestVariousNumberFormats()
        {
            string script = @"---
<<set $int = 42>>
<<set $float = 3.14>>
<<set $zero = 0>>
<<set $negative = -123>>
<<set $decimal = 0.001>>
<<set $scientific = 1.23e-4>>
===";

            var tokens = TokenizeScript(script);

            var numberTokens = tokens.Where(t => t.Type == TokenType.NUMBER).ToList();
            Assert.IsTrue(numberTokens.Count >= 5, "åº”è¯¥è¯†åˆ«å‡ºè‡³å°‘5ä¸ªæ•°å­—");
            
            // éªŒè¯æ•´æ•°ã€æµ®ç‚¹æ•°ã€é›¶å€¼ç­‰
            Assert.IsTrue(numberTokens.Any(t => t.Value == "42"), "åº”è¯¥åŒ…å«æ•´æ•°");
            Assert.IsTrue(numberTokens.Any(t => t.Value == "3.14"), "åº”è¯¥åŒ…å«æµ®ç‚¹æ•°");
            Assert.IsTrue(numberTokens.Any(t => t.Value == "0"), "åº”è¯¥åŒ…å«é›¶å€¼");
        }

        // === æ–°å¢é«˜çº§è¾¹ç•Œæµ‹è¯• ===
        [Test]
        public void TestTokenPositionAccuracy()
        {
            string script = @"node: test
---
è§’è‰²: æµ‹è¯•
===";

            var tokens = TokenizeScript(script);

            // éªŒè¯Tokenä½ç½®ä¿¡æ¯
            AssertTokensWithPosition(tokens.Take(4).ToList(),
                (TokenType.IDENTIFIER, "node", 1, 1),
                (TokenType.METADATA_SEPARATOR, ":", 1, 5),
                (TokenType.TEXT, "test", 1, 7),
                (TokenType.NODE_START, "---", 2, 1)
            );
        }

        [Test]
        public void TestCrossplatformLineEndings()
        {
            string scriptWindows = "node: test\r\n---\r\nè§’è‰²: å¯¹è¯\r\n===";
            string scriptUnix = "node: test\n---\nè§’è‰²: å¯¹è¯\n===";
            string scriptMac = "node: test\r---\rè§’è‰²: å¯¹è¯\r===";

            var tokensWindows = TokenizeScript(scriptWindows);
            var tokensUnix = TokenizeScript(scriptUnix);
            var tokensMac = TokenizeScript(scriptMac);

            // æ‰€æœ‰å¹³å°åº”è¯¥ç”Ÿæˆç›¸åŒçš„éæ¢è¡ŒTokenç»“æ„
            var nonNewlineWindows = tokensWindows.Where(t => t.Type != TokenType.NEWLINE).ToArray();
            var nonNewlineUnix = tokensUnix.Where(t => t.Type != TokenType.NEWLINE).ToArray();
            var nonNewlineMac = tokensMac.Where(t => t.Type != TokenType.NEWLINE).ToArray();

            Assert.AreEqual(nonNewlineWindows.Length, nonNewlineUnix.Length, "Windowså’ŒUnixåº”è¯¥ç”Ÿæˆç›¸åŒæ•°é‡çš„Token");
            Assert.AreEqual(nonNewlineUnix.Length, nonNewlineMac.Length, "Unixå’ŒMacåº”è¯¥ç”Ÿæˆç›¸åŒæ•°é‡çš„Token");
        }

        [Test]
        public void TestColonContextSensitivity()
        {
            string script = @"---
:æ—ç™½å†’å·å¼€å¤´
è§’è‰²å: å¯¹è¯å†…å®¹
æ™®é€š:æ–‡æœ¬:ä¸­é—´:æœ‰:å†’å·
===";

            var tokens = TokenizeScript(script);

            // æ£€æŸ¥å†’å·åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„å¤„ç†
            var colonTokens = tokens.Where(t => t.Type == TokenType.COLON).ToList();
            Assert.IsTrue(colonTokens.Count >= 2, "åº”è¯¥è¯†åˆ«å‡ºå¤šä¸ªå†’å·");
            
            // ç¬¬ä¸€ä¸ªåº”è¯¥æ˜¯è¡Œé¦–æ—ç™½æ ‡è®°ï¼Œç¬¬äºŒä¸ªåº”è¯¥æ˜¯å¯¹è¯åˆ†éš”ç¬¦
            Assert.AreEqual(1, colonTokens[0].Column, "ç¬¬ä¸€ä¸ªå†’å·åº”è¯¥åœ¨è¡Œé¦–");
        }

        [Test]
        public void TestArrowInText()
        {
            string script = @"---
æ™®é€šæ–‡æœ¬ -> ä¸æ˜¯é€‰é¡¹ç®­å¤´
-> çœŸæ­£çš„é€‰é¡¹
===";

            var tokens = TokenizeScript(script);

            var arrowTokens = tokens.Where(t => t.Type == TokenType.ARROW).ToList();
            Assert.AreEqual(1, arrowTokens.Count, "åº”è¯¥åªè¯†åˆ«ä¸€ä¸ªçœŸæ­£çš„ç®­å¤´ï¼ˆåœ¨è¡Œé¦–çš„ï¼‰");

            var textTokens = tokens.Where(t => t.Type == TokenType.TEXT).ToList();
            var arrowInText = textTokens.Any(t => t.Value.Contains("->"));
            Assert.IsTrue(arrowInText, "æ–‡æœ¬ä¸­çš„ç®­å¤´åº”è¯¥ä½œä¸ºæ™®é€šæ–‡æœ¬å¤„ç†");
        }

        [Test]
        public void TestHashInText()
        {
            string script = @"---
è§’è‰²: è¿™æ˜¯\#å·åœ¨æ–‡æœ¬ä¸­çš„æƒ…å†µ #real_tag
===";

            var tokens = TokenizeScript(script);

            var hashTokens = tokens.Where(t => t.Type == TokenType.HASH).ToList();
            var textTokens = tokens.Where(t => t.Type == TokenType.TEXT).ToList();

            Assert.IsTrue(textTokens.Any(t => t.Value.Contains("#å·")), "æ–‡æœ¬ä¸­çš„#å·åº”è¯¥è¢«åŒ…å«åœ¨æ–‡æœ¬ä¸­");
            Assert.IsTrue(hashTokens.Count >= 1, "ç‹¬ç«‹çš„#æ ‡ç­¾åº”è¯¥è¢«è¯†åˆ«");
        }

        [Test]
        public void TestBracketEdgeCases()
        {
            string script = @"---
è§’è‰²: æ–¹æ‹¬å·[text]å’Œåœ†æ‹¬å·(text)å’ŒèŠ±æ‹¬å·{$var}
===";

            var tokens = TokenizeScript(script);

            var braceTokens = tokens.Where(t => t.Type == TokenType.LEFT_BRACE || t.Type == TokenType.RIGHT_BRACE).ToList();
            Assert.AreEqual(2, braceTokens.Count, "åº”è¯¥åªè¯†åˆ«æ’å€¼çš„èŠ±æ‹¬å·");

            var textTokens = tokens.Where(t => t.Type == TokenType.TEXT).ToList();
            Assert.IsTrue(textTokens.Any(t => t.Value.Contains("[text]")), "æ–¹æ‹¬å·åº”è¯¥ä½œä¸ºæ™®é€šæ–‡æœ¬");
            Assert.IsTrue(textTokens.Any(t => t.Value.Contains("(text)")), "åœ†æ‹¬å·åº”è¯¥ä½œä¸ºæ™®é€šæ–‡æœ¬");
        }

        [Test]
        public void TestUnterminatedStringRecovery()
        {
            string script = @"---
<<set $msg = ""æœªç»“æŸçš„å­—ç¬¦ä¸²
è§’è‰²: åç»­æ­£å¸¸å†…å®¹
===";

            // éªŒè¯é”™è¯¯æ¢å¤æœºåˆ¶
            var tokens = TokenizeScript(script);
            Assert.IsNotNull(tokens, "æœªç»“æŸçš„å­—ç¬¦ä¸²ä¸åº”å¯¼è‡´å´©æºƒ");
            Assert.IsTrue(tokens.Any(t => t.Type == TokenType.EOF), "åº”è¯¥èƒ½åˆ°è¾¾EOF");
            Assert.IsTrue(tokens.Any(t => t.Type == TokenType.TEXT && t.Value.Contains("åç»­")), "åº”è¯¥èƒ½ç»§ç»­è§£æåç»­å†…å®¹");
        }

        [Test]
        public void TestEmptyInterpolationAndEdgeCases()
        {
            string script = @"---
è§’è‰²: ç©ºæ’å€¼{}æµ‹è¯•ï¼Œå¤šé‡æ’å€¼{$a}{$b}ï¼ŒåµŒå¥—æ–‡æœ¬{$name}å’Œ{$value}æ··åˆ
===";

            var tokens = TokenizeScript(script);

            var braceTokens = tokens.Where(t => t.Type == TokenType.LEFT_BRACE || t.Type == TokenType.RIGHT_BRACE).ToList();
            Assert.AreEqual(10, braceTokens.Count, "åº”è¯¥è¯†åˆ«æ‰€æœ‰å¤§æ‹¬å·ï¼ˆ5å¯¹ï¼‰");
            
            var variableTokens = tokens.Where(t => t.Type == TokenType.VARIABLE).ToList();
            Assert.AreEqual(4, variableTokens.Count, "åº”è¯¥æœ‰4ä¸ªå˜é‡ï¼ša, b, name, value");
        }

        [Test]
        public void TestComplexIdentifierSupport()
        {
            string script = @"test_node_123: value
node_æµ‹è¯•: ä¸­æ–‡å€¼
_special: ä¸‹åˆ’çº¿å¼€å¤´
123invalid: æ•°å­—å¼€å¤´
---
å†…å®¹
===";

            var tokens = TokenizeScript(script);

            var identifiers = tokens.Where(t => t.Type == TokenType.IDENTIFIER).ToList();
            Assert.IsTrue(identifiers.Any(t => t.Value == "test_node_123"), "åº”è¯¥æ”¯æŒä¸‹åˆ’çº¿å’Œæ•°å­—çš„æ ‡è¯†ç¬¦");
            Assert.IsTrue(identifiers.Any(t => t.Value == "node_æµ‹è¯•"), "åº”è¯¥æ”¯æŒä¸­æ–‡å­—ç¬¦çš„æ ‡è¯†ç¬¦");
            Assert.IsTrue(identifiers.Any(t => t.Value == "_special"), "åº”è¯¥æ”¯æŒä¸‹åˆ’çº¿å¼€å¤´çš„æ ‡è¯†ç¬¦");
        }

        // === æç«¯è¾¹ç•Œæµ‹è¯• ===
        [Test]
        public void TestExtremeNestingDepth()
        {
            // åˆ›å»º15å±‚åµŒå¥—ç»“æ„
            var script = @"---";
            for (int i = 0; i < 15; i++)
            {
                script += "\n" + new string(' ', i * 4) + $"-> ç¬¬{i+1}å±‚";
            }
            script += "\n" + new string(' ', 15 * 4) + "æœ€æ·±å±‚å†…å®¹";
            script += "\n===";

            // éªŒè¯ææ·±åµŒå¥—ä¸ä¼šå´©æºƒ
            var tokens = TokenizeScript(script);
            Assert.IsNotNull(tokens, "ææ·±åµŒå¥—ä¸åº”å´©æºƒ");
            Assert.IsTrue(tokens.Any(t => t.Type == TokenType.EOF), "åº”è¯¥æ­£å¸¸ç»“æŸ");
            
            var arrowTokens = tokens.Where(t => t.Type == TokenType.ARROW).ToList();
            Assert.AreEqual(15, arrowTokens.Count, "åº”è¯¥æ­£ç¡®è¯†åˆ«15ä¸ªé€‰é¡¹ç®­å¤´");
        }

        [Test]
        public void TestMalformedCommandRecovery()
        {
            string script = @"---
<<incomplete command without ending
æ­£å¸¸æ–‡æœ¬
<<set $valid = true>>
===";

            // éªŒè¯é”™è¯¯å‘½ä»¤åçš„æ¢å¤èƒ½åŠ›
            var tokens = TokenizeScript(script);
            Assert.IsNotNull(tokens, "é”™è¯¯å‘½ä»¤ä¸åº”å´©æºƒ");
            Assert.IsTrue(tokens.Any(t => (t.Type is TokenType.TEXT or TokenType.IDENTIFIER) && t.Value.Contains("æ­£å¸¸")), "åº”è¯¥èƒ½ç»§ç»­è§£ææ­£å¸¸æ–‡æœ¬");
        }

        [Test]
        public void TestUtf8NoBomHandling()
        {
            // UTF-8 BOM + æ­£å¸¸å†…å®¹
            string script = "\uFEFFnode: test\n---\nè§’è‰²: å¯¹è¯\n===";

            var tokens = TokenizeScript(script);

            // BOM æš‚ä¸å…¼å®¹
            Assert.IsFalse(tokens.Any(t => t.Type == TokenType.INDENT && t.Value == "node"), "åº”è¯¥è¯†åˆ«èŠ‚ç‚¹æ ‡è¯†ç¬¦é”™è¯¯");
            Assert.IsTrue(tokens.Any(t => t.Type == TokenType.TEXT && t.Value == "test"), "åº”è¯¥æ­£ç¡®è¯†åˆ«æ–‡æœ¬å†…å®¹");
        }

        [Test]
        public void TestVeryLongLine()
        {
            // åˆ›å»ºä¸€ä¸ªéå¸¸é•¿çš„è¡Œï¼ˆ5000å­—ç¬¦ï¼‰
            var longLine = new string('A', 5000);
            string script = $@"---
è§’è‰²: {longLine}
===";

            var tokens = TokenizeScript(script);
            
            var longTextToken = tokens.FirstOrDefault(t => t.Type == TokenType.TEXT && t.Value.Length > 4000);
            Assert.IsNotNull(longTextToken, "åº”è¯¥èƒ½å¤„ç†éå¸¸é•¿çš„è¡Œ");
        }

        [Test]
        public void TestSpecialWhitespaceCharacters()
        {
            // åŒ…å«å„ç§ç©ºç™½å­—ç¬¦ï¼šåˆ¶è¡¨ç¬¦ã€å…¨è§’ç©ºæ ¼ã€æ— åˆ†éš”ç©ºæ ¼ç­‰
            string script = "node:\u3000test\n---\nè§’è‰²:\u00A0æµ‹è¯•\u2009å†…å®¹\n===";

            var tokens = TokenizeScript(script);

            // éªŒè¯å„ç§ç©ºç™½å­—ç¬¦è¢«æ­£ç¡®å¤„ç†
            Assert.IsTrue(tokens.Any(t => t.Type == TokenType.IDENTIFIER && t.Value == "node"), "åº”è¯¥æ­£ç¡®è¯†åˆ«æ ‡è¯†ç¬¦");
            Assert.IsTrue(tokens.Any(t => t.Type == TokenType.TEXT && t.Value.Contains("æµ‹è¯•")), "åº”è¯¥æ­£ç¡®å¤„ç†ç‰¹æ®Šç©ºç™½å­—ç¬¦");
        }

        [Test]
        public void TestMixedQuoteRecovery()
        {
            string script = @"---
<<set $msg1 = ""åŒå¼•å·å¼€å§‹'å•å¼•å·ç»“æŸ>>
<<set $msg2 = 'å•å¼•å·å¼€å§‹""åŒå¼•å·ç»“æŸ>>
æ­£å¸¸å†…å®¹
===";

            // éªŒè¯å¼•å·ä¸åŒ¹é…çš„é”™è¯¯æ¢å¤
            var tokens = TokenizeScript(script);
            Assert.IsNotNull(tokens, "å¼•å·ä¸åŒ¹é…ä¸åº”å´©æºƒ");
            Assert.IsTrue(tokens.Any(t => t.Type == TokenType.TEXT && t.Value.Contains("æ­£å¸¸")), "åº”è¯¥èƒ½ç»§ç»­è§£æåç»­å†…å®¹");
        }
    }
}
